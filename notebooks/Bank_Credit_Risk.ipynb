{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9916254-7a22-43ef-b8e7-d6a7e50f8ecd",
   "metadata": {},
   "source": [
    "## German Credit Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bc10b-5123-47a0-8bb2-2d07640753fa",
   "metadata": {},
   "source": [
    "Required Libraries and Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa60d880-cc0e-457d-a36d-4664d11c5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78214c82-644b-429a-8e93-ca75cf6d81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('german_credit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64fba6d1-01c1-44c3-948a-227038c53db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1736</td>\n",
       "      <td>12</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>40</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>3857</td>\n",
       "      <td>30</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>38</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>804</td>\n",
       "      <td>12</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>1845</td>\n",
       "      <td>45</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>moderate</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4576</td>\n",
       "      <td>45</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Age     Sex  Job Housing Saving accounts Checking account  \\\n",
       "0             0   67    male    2     own             NaN           little   \n",
       "1             1   22  female    2     own          little         moderate   \n",
       "2             2   49    male    1     own          little              NaN   \n",
       "3             3   45    male    2    free          little           little   \n",
       "4             4   53    male    2    free          little           little   \n",
       "..          ...  ...     ...  ...     ...             ...              ...   \n",
       "995         995   31  female    1     own          little              NaN   \n",
       "996         996   40    male    3     own          little           little   \n",
       "997         997   38    male    2     own          little              NaN   \n",
       "998         998   23    male    2    free          little           little   \n",
       "999         999   27    male    2     own        moderate         moderate   \n",
       "\n",
       "     Credit amount  Duration              Purpose  Risk  \n",
       "0             1169         6             radio/TV  good  \n",
       "1             5951        48             radio/TV   bad  \n",
       "2             2096        12            education  good  \n",
       "3             7882        42  furniture/equipment  good  \n",
       "4             4870        24                  car   bad  \n",
       "..             ...       ...                  ...   ...  \n",
       "995           1736        12  furniture/equipment  good  \n",
       "996           3857        30                  car  good  \n",
       "997            804        12             radio/TV  good  \n",
       "998           1845        45             radio/TV   bad  \n",
       "999           4576        45                  car  good  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc4dd2d7-d159-433c-a0bf-ad3891632166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Age', 'Sex', 'Job', 'Housing', 'Saving accounts',\n",
       "       'Checking account', 'Credit amount', 'Duration', 'Purpose', 'Risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a101a-7b85-429c-a8e2-b0c8baa92dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483169e3-2309-444e-9078-c88a6c4f1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f14774-3c0c-4cb3-b42a-44f5699cec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  there are many non Numeric Columns in dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e9de8-138a-4d53-a44c-fa0e9641f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all column names\n",
    "columns = df.columns\n",
    "\n",
    "# Initialize an empty list for object-type columns\n",
    "obj_col = []\n",
    "\n",
    "# Loop through columns and check for object type\n",
    "for col in columns:\n",
    "    if df[col].dtype == 'O':  \n",
    "        obj_col.append(col)\n",
    "\n",
    "# Print the list of object columns\n",
    "print(obj_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593a6b2-dda1-44e6-91e5-7584299777b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list for numeric columns\n",
    "numeric_col = []\n",
    "\n",
    "# Loop through columns and check for numeric types\n",
    "for col in columns:\n",
    "    if df[col].dtype in ['int64', 'float64']:  # Check for numeric types\n",
    "        numeric_col.append(col)\n",
    "\n",
    "# Print the list of numeric columns\n",
    "print(numeric_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e58cd9-7058-409f-bc9a-334230a7eff7",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686772cb-748a-4783-97d0-18a491391c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the \"Unnamed columns\" no need of it\n",
    "\n",
    "df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0f7d0-13fc-4616-910d-b263dffe1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f07f6e-df8e-49b8-9cdf-899add0eee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Saving accounts'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09812c9c-cba3-4759-87c8-4cb232b70970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc2d03-994f-4609-a57e-94db73a3f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1d2ff-205f-47ae-bcb7-611999340b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for 'Saving accounts' and 'Checking account' with the mode\n",
    "## df['Saving accounts'].fillna(df['Saving accounts'].mode()[0], inplace=True)\n",
    "## df['Checking account'].fillna(df['Checking account'].mode()[0], inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing values\n",
    "# df.dropna(subset=['Saving accounts', 'Checking account'], inplace=True)\n",
    "##  but after droping this columns our data becomes in (522, 10) shape so this is not good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc90d6-bc33-477c-871a-c41a3a5238da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## try another methode to impute missing value because model is not giving better accurecy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74faa2da-8e08-4526-9276-afcaefc778a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encoding 'Saving accounts' column\n",
    "saving_accounts_mapping = {'little': 0, 'moderate': 1, 'rich': 2, 'quite rich': 3}\n",
    "df['Saving accounts'] = df['Saving accounts'].map(saving_accounts_mapping)\n",
    "\n",
    "# Manually encoding 'Checking account' column\n",
    "checking_account_mapping = {'little': 0, 'moderate': 1, 'rich': 2}\n",
    "df['Checking account'] = df['Checking account'].map(checking_account_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997aa253-19e8-4446-aadc-37e23e7a6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Initialize KNN imputer with n_neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Impute the missing values\n",
    "df[['Saving accounts', 'Checking account']] = imputer.fit_transform(df[['Saving accounts', 'Checking account']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0ac59-f0d6-4ff6-9577-c4a4bfbe71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f1a0e-7ee6-4317-b5a7-bb3dbd157406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90e6b1-d1f1-4c6f-91d6-c69d7268d235",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbfede-6489-4e29-99f7-48f0d3721bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b4caa4-cdb4-4a8c-86f9-592c5a9dc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frequency distribution for categorical columns\n",
    "print(df['Sex'].value_counts())\n",
    "print()\n",
    "print(df['Housing'].value_counts())\n",
    "print()\n",
    "print(df['Saving accounts'].value_counts())\n",
    "print()\n",
    "print(df['Checking account'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19556d4-ae56-469f-8026-9669677ed532",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b1d25-1728-4581-9471-30c821e3236b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram for numerical features\n",
    "df[['Age', 'Job', 'Credit amount', 'Duration']].hist(bins=20, figsize=(10, 6))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96257e02-264a-4a0b-b003-2fd3f22f530c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Age\n",
    "- The age distribution is roughly bell-shaped, with a peak between 30 and 40 years.\n",
    "- There is a noticeable decrease in frequency for ages above 50.\n",
    "- Very few individuals are represented in the extreme age ranges (under 20 and over 70).\n",
    "\n",
    "### Job\n",
    "- The job distribution shows a strong concentration in one category (the most common job type), likely representing a majority of the dataset.\n",
    "- Other job categories are present but have significantly lower counts, indicating an uneven distribution of job types.\n",
    "\n",
    "### Credit Amount\n",
    "- The credit amount distribution is positively skewed, with a large number of individuals borrowing smaller amounts (below 2,500).\n",
    "- A sharp decline in frequency is observed as credit amounts increase, suggesting that fewer individuals take out larger loans.\n",
    "- There are a few outliers with very high amounts, but they are not common.\n",
    "\n",
    "### Duration\n",
    "- The duration histogram shows multiple peaks, with the highest frequencies at around 10 and 20 months, indicating that many loans have shorter terms.\n",
    "- The distribution also drops off significantly for longer durations, with very few loans exceeding 50 months.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85333f9-52d4-4c72-a16d-4056d775d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for numerical features to check for outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[['Age', 'Job', 'Credit amount', 'Duration']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cf3ba-d116-42be-8bb7-6cfb32dbf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "## outliers in Credit amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4d1d9-fb18-49bc-ad46-d12eea01d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for categorical features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Sex', data=df)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Housing', data=df)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Risk', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524f44e-a742-423e-ab3f-53f68a424faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imbalance data (good/bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc16979-2566-4d54-9e8b-062a00a6b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot between two numerical features\n",
    "sns.scatterplot(x='Age', y='Credit amount', data=df)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903e10f-70c7-4ccb-a161-72b3ab48e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Age between 20 and 30  have credit amount 2500 and most of people belong to this age gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730091a-8a50-410c-bd45-c0ba7f6ed214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numerical columns\n",
    "correlation = df[['Age', 'Job', 'Credit amount', 'Duration']].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7ca6e-e27d-4d3a-86a1-a501de6307bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot between numerical and categorical variables\n",
    "sns.boxplot(x='Risk', y='Credit amount', data=df)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd30f41-e70f-4ef0-9d62-e7ae1a939d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## risk free (good)  credit amount mostly lie between 2500 and 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607bb6f-515d-4679-a2e2-e13832f4949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='Risk', y='Age', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524eb1a3-30b2-4475-9518-2c2cff4b0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation between two categorical features\n",
    "print(pd.crosstab(df['Sex'], df['Housing']))\n",
    "\n",
    "# Stacked bar plot\n",
    "pd.crosstab(df['Sex'], df['Housing']).plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeed5ce-c65b-44fa-9fec-1294ab288395",
   "metadata": {},
   "outputs": [],
   "source": [
    "## most of house own by male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f173e1-c5dc-4766-afef-97f43edc704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['Age', 'Credit amount', 'Duration']])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570f0ac-bbfb-4041-8c59-fa705377d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to check for outliers\n",
    "sns.boxplot(data=df[['Age', 'Job', 'Credit amount', 'Duration']])\n",
    "plt.show()\n",
    "\n",
    "# Z-score method to identify outliers\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df[['Age', 'Credit amount', 'Duration']]))\n",
    "outliers = (z_scores > 3).sum(axis=0)\n",
    "print(\"Outliers detected in columns:\", outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e815ba-01f3-4dbb-af45-f8050112bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness of numeric columns\n",
    "print(df[['Age', 'Job', 'Credit amount', 'Duration']].skew())\n",
    "\n",
    "# Apply log transformation or other methods if needed\n",
    "df['Credit amount'] = np.log1p(df['Credit amount'])  # Log transformation to handle skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd5396-5d9f-434e-82c1-4833df145233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a4c3b-21e2-460b-8c94-b28510e887ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Checking account'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c198a-8256-4358-b4ec-e19c44820850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76558-343c-4ef4-9709-c45d87dc6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (\"student\", \"young\", \"adult\", \"senior\")\n",
    "groups = pd.cut(df[\"Age\"], labels=labels, bins=(18, 25, 35, 60, 120), ordered=True)\n",
    "df[\"Age group\"] = groups\n",
    "\n",
    "sns.countplot(data=df, y=\"Age group\", hue=\"Sex\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719410d-4c9f-431b-b5e5-1bb0679bf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data_frame=df, x=\"Purpose\", color=\"Sex\", histnorm=\"percent\", barmode=\"group\", width=800)\n",
    "fig.update_layout(title=\"Distribution of Purpose by Sex\", title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b1616-ec31-4858-b8c9-c0293f76171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=df, x=\"Purpose\", y=\"Credit amount\", color=\"Sex\", width=900)\n",
    "fig.update_layout(title=\"Credit amount by Purpose and Risk\", title_x=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "013e388c-5c1d-4ccf-9684-596923d3f154",
   "metadata": {},
   "source": [
    "## Findings:\n",
    "\n",
    "The male/female proportion is 69%/31% respectively.\n",
    "Considering a lifetime span, females tend to make loan sooner than males.\n",
    "The main reasons for loans area car and radio/tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c8a68-3314-4a8a-8817-185c646d77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.boxplot(data=df, x=\"Risk\", y=\"Credit amount\", ax=ax0)\n",
    "sns.boxplot(data=df, x=\"Risk\", y=\"Duration\", ax=ax1)\n",
    "fig.suptitle(\"Credit amount and duration influence on credit risk\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce530f0-5f3a-44dd-b028-291bf6b255e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(16, 4))\n",
    "sns.histplot(data=df, x=\"Age\", hue=\"Risk\", multiple=\"fill\", bins=6, ax=ax0)\n",
    "sns.histplot(data=df, x=\"Sex\", hue=\"Risk\", multiple=\"fill\", ax=ax1)\n",
    "sns.histplot(data=df, x=\"Purpose\", hue=\"Risk\", multiple=\"fill\", ax=ax2)\n",
    "sns.histplot(data=df, x=\"Housing\", hue=\"Risk\", multiple=\"fill\", ax=ax3)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation= 90)\n",
    "fig.suptitle(\"Risk proportion by age and sex\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04d6cdea-48bc-4a63-8e45-5adf2a5d676c",
   "metadata": {},
   "source": [
    "Findings:\n",
    "\n",
    "Credit with higher amount and duration has a greater risk becoming a bad credit.\n",
    "Rich people are less probable of becoming bad credit.\n",
    "Young (20-30) and old (60+) have a slightly greater chance becoming credit defaulter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ab3e5-0d4b-487c-aebb-5ede164a731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363d0da-95e0-4d3b-94e2-81077c4c2c65",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800304b-0668-4133-a68c-9f2606253d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443fc47-d6c3-4581-9d29-5b3f2c954186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81745dfd-4e7b-45b8-968d-2b6aac701aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Age group']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"Unique values in {col}: {df[col].unique()}\")\n",
    "    else:\n",
    "        print(f\"Column {col} not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49c13458-6c70-4d63-94a3-57def9c6e937",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binary Encoding for 'Sex'\n",
    "df['Sex'] = df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "df['Risk'] = df['Risk'].apply(lambda x: 1 if x == 'good' else 0)\n",
    "# Columns to apply Label Encoding\n",
    "label_encoding_cols = ['Job','Housing', 'Saving accounts', 'Checking account', 'Purpose','Age group']\n",
    "\n",
    "# Initialize Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to each column\n",
    "for col in label_encoding_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Verify the encoding\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac91be-f5e9-4878-9ce9-a081f84a3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to change the incoding methods of features to get get better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb73ee-4e49-4b61-9f2f-c8e699180c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca4b25-2272-41c5-a76a-ed654fe9aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binary Encoding for 'Sex'\n",
    "df['Sex'] = df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "df['Risk'] = df['Risk'].apply(lambda x: 1 if x == 'good' else 0)\n",
    "\n",
    "# Columns to apply Label Encoding\n",
    "label_encoding_cols = ['Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Age group']\n",
    "\n",
    "# Initialize Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to each column\n",
    "for col in label_encoding_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Verify the encoding\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00dcfa-b242-4a4d-ba5c-ae67bef6ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Risk'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e1615-7bde-4644-9015-be727968a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdd434-a3d9-4f29-8f9c-de258f8d90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d282eae-962b-4f85-bb24-42dfea8cf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cols = ['Age', 'Sex','Job','Housing','Saving accounts','Checking account','Purpose','Age group','Credit amount', 'Duration']  # Columns to scale\n",
    "df[cols] = scaler.fit_transform(df[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef7222-b421-4209-b885-83dcb215d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a4ee7-7608-47d2-bd14-b587fc35dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Adjust the grid size based on your number of features\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot scatter plots for each numerical feature\n",
    "numerical_features = ['Age', 'Credit amount', 'Duration', 'Saving accounts', 'Checking account', 'Housing']\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    sns.scatterplot(x=df[feature], y=df['Risk'], ax=axes[i])\n",
    "    axes[i].set_title(f'Scatter Plot: {feature} vs Risk')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Risk')\n",
    "\n",
    "# Adjust layout for better visualization\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d8739-f3e3-4625-a504-9ccbce0a16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Linear Relationship with target veriable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c3077-7368-4272-b26e-68ec04629dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Step 1: Select the independent variables (exclude the target variable 'Risk')\n",
    "X = df.drop(columns=['Risk'])\n",
    "\n",
    "# Step 2: Add a constant to the data (for the intercept in the VIF calculation)\n",
    "X = add_constant(X)\n",
    "\n",
    "# Step 3: Calculate the VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Step 4: Display the results\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9ffb3-e66b-4bcf-b69f-c9a12bab8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF is below 5 so no problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56745c8-f612-43a9-b2b7-94253b1758ff",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b44f222-9f83-488f-a647-4d8fcc76c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X = df.drop('Risk', axis=1)  # Features\n",
    "y = df['Risk']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f4e97-2111-4ff7-b227-f821899dc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Risk'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5e2f5-8dc4-4658-a849-f6a3fc5db73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imbalance DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ca002-d93d-4c03-a7b2-9c9d52f05824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761ffc8-3241-4618-93d0-f2d51ee31aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3580d7-7720-4208-afdf-dcd2cd914f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b4a5b-38c2-4ba4-be7b-144433808f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522430b-bb9e-4867-9c32-0a3c9f1ebdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e979b8d-e7d6-4f29-ac96-f16122a84d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3baea8-848f-4929-87a4-3ecb6332bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable after SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317d7ab-66a2-47b6-aeb4-e413afd0663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Risk'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4d6dd-19c7-4f19-b56b-128372377fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a7752-c9a8-4c89-a3d4-334c4084c1a4",
   "metadata": {},
   "source": [
    "## 1 Random Forest Classifier\n",
    "\n",
    "## 2 Gradient Boosting Classifier (XGBoost)\n",
    "\n",
    "## 3 Support Vector Machine (SVM)\n",
    "\n",
    "## 4 K-Nearest Neighbors (KNN)\n",
    "\n",
    "## 5 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3dc2cf1-53f5-4921-8175-3541e3d4b136",
   "metadata": {},
   "source": [
    "we will try this models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88d963-f2e6-45a1-846c-cfa93401fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(columns=['Risk'])\n",
    "y = df['Risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872dff38-b430-4508-bbe0-627e26443bfc",
   "metadata": {},
   "source": [
    "# 1 Random Forest Classifier¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e958818-8d23-48c2-bf59-ed9ec2cd22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Best Params:\", grid_search_rf.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279715c-52f0-4ebf-830d-489ccf726f4e",
   "metadata": {},
   "source": [
    "# 2 Gradient Boosting Classifier (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f63c4-fd50-4e3f-860b-1eb443ccb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab5204-54ca-4fb9-b300-9f73b8ab3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Best Params:\", grid_search_xgb.best_params_)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c01c2d-2212-45d2-bb04-efae7698be7d",
   "metadata": {},
   "source": [
    "## 3. Support Vector Machine (SVM) with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abb4a4-2baa-4d23-877a-f07d0acf0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [3, 4, 5]\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid_svm, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Best Params:\", grid_search_svm.best_params_)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabe998-d50d-4b7a-9f7a-76e6bdde6a1c",
   "metadata": {},
   "source": [
    "## 4. K-Nearest Neighbors (KNN) with Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730738e6-9829-49d5-a45b-74af0e1950ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid_knn, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "print(\"KNN Best Params:\", grid_search_knn.best_params_)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abbb53-9d08-473b-bbcf-0127c7edaa3a",
   "metadata": {},
   "source": [
    "## 5. Decision Tree Classifier with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec251092-00ba-4735-aa0f-ed649e053d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Best Params:\", grid_search_dt.best_params_)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f568c80-f195-4c21-8f50-c94fdb4f9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Define the model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Hyperparameters grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gb, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator\n",
    "best_gb = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_gb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bd469-dea8-47ec-ae7e-51b386f39f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define individual models\n",
    "model1 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
    "model2 = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "model3 = SVC(kernel='linear', probability=True)\n",
    "model4 = LogisticRegression()\n",
    "\n",
    "# Create a voting classifier (soft voting: predicted probability, can use hard for majority voting)\n",
    "voting_clf = VotingClassifier(estimators=[('gb', model1), ('rf', model2), ('svc', model3), ('lr', model4)], voting='soft')\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the voting classifier\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Voting Classifier Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df2652-ece9-42c5-8346-2beaae3bd08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42))\n",
    "]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa23c56-ec84-4d06-b3ab-3a6a448fbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9106b2c4-4ac6-47ca-a0ba-1440287e7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274d568-0f1d-42d3-a493-8ccf3a4b7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Step 1: Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve MongoDB URL, Database Name, and Collection Name from environment variables\n",
    "uri = \"mongodb+srv://acashtech28:akash123@sambhajinagar.a2pwo.mongodb.net/?retryWrites=true&w=majority&appName=sambhajinagar\"\n",
    "DATABASE_NAME = \"German_Bank\"\n",
    "COLLECTION_NAME = \"credit_risk\"\n",
    "\n",
    "# Step 2: Ensure the MongoDB URI is available\n",
    "if uri is None:\n",
    "    raise ValueError(\"MONGO_DB_URL environment variable is not set.\")\n",
    "if DATABASE_NAME is None:\n",
    "    raise ValueError(\"MONGO_DATABASE_NAME environment variable is not set.\")\n",
    "if COLLECTION_NAME is None:\n",
    "    raise ValueError(\"MONGO_COLLECTION_NAME environment variable is not set.\")\n",
    "\n",
    "# Step 3: Establish connection with MongoDB\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Step 4: Path to the CSV file you want to upload\n",
    "csv_file_path = r\"german_credit_data.csv\"  # Update the path if necessary\n",
    "\n",
    "# Step 5: Read CSV file into a Pandas DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 6: Check and drop any unnamed columns (typically, index columns in CSV files)\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "# Step 7: Convert the DataFrame to JSON format that MongoDB accepts (list of dictionaries)\n",
    "json_record = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Step 8: Insert the records into MongoDB collection\n",
    "try:\n",
    "    # Insert data into the specified collection\n",
    "    client[DATABASE_NAME][COLLECTION_NAME].insert_many(json_record)\n",
    "    print(\"Data inserted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting data into MongoDB: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f14b69-b1a7-4944-beee-f0d5624d8c17",
   "metadata": {},
   "source": [
    "## data preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8810b2-02d2-408c-a429-3ea1d0b19000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('german_credit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd822a1-daf5-4ee1-9f75-82ee99623a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.441354</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.997998</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.393114</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.995996</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.085739</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.993994</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2.133883</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.991992</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.978421</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.991992</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.223842</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.589815</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.581375</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.997998</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.182027</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865637</td>\n",
       "      <td>2.25</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Age  Sex  Job  Housing  Saving accounts  \\\n",
       "0     -1.000000  2.266667  0.0  0.0      0.0              2.0   \n",
       "1     -0.997998 -0.733333 -1.0  0.0      0.0              0.0   \n",
       "2     -0.995996  1.066667  0.0 -1.0      0.0              0.0   \n",
       "3     -0.993994  0.800000  0.0  0.0     -1.0              0.0   \n",
       "4     -0.991992  1.333333  0.0  0.0     -1.0              0.0   \n",
       "..          ...       ...  ...  ...      ...              ...   \n",
       "995    0.991992 -0.133333 -1.0 -1.0      0.0              0.0   \n",
       "996    0.993994  0.466667  0.0  1.0      0.0              0.0   \n",
       "997    0.995996  0.333333  0.0  0.0      0.0              0.0   \n",
       "998    0.997998 -0.666667  0.0  0.0     -1.0              0.0   \n",
       "999    1.000000 -0.400000  0.0  0.0      0.0              0.5   \n",
       "\n",
       "     Checking account  Credit amount  Duration  Purpose  Risk  \n",
       "0           -0.333333      -0.441354     -1.00     0.50   0.0  \n",
       "1            0.000000       1.393114      2.50     0.50  -1.0  \n",
       "2            0.666667      -0.085739     -0.50     0.00   0.0  \n",
       "3           -0.333333       2.133883      2.00     0.25   0.0  \n",
       "4           -0.333333       0.978421      0.50    -0.50  -1.0  \n",
       "..                ...            ...       ...      ...   ...  \n",
       "995          0.666667      -0.223842     -0.50     0.25   0.0  \n",
       "996         -0.333333       0.589815      1.00    -0.50   0.0  \n",
       "997          0.666667      -0.581375     -0.50     0.50   0.0  \n",
       "998         -0.333333      -0.182027      2.25     0.50  -1.0  \n",
       "999          0.000000       0.865637      2.25    -0.50   0.0  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "class LabelEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_copy.columns:\n",
    "                le = LabelEncoder()\n",
    "                X_copy[col] = le.fit_transform(X_copy[col])\n",
    "        return X_copy\n",
    "\n",
    "class BinaryEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_copy.columns:\n",
    "                X_copy[col] = X_copy[col].apply(lambda x: 1 if x == 'good' or x == 'male' else 0)\n",
    "        return X_copy\n",
    "\n",
    "# ... (rest of the pipeline and transformation code)\n",
    "\n",
    "label_encode_columns = ['Housing', 'Saving accounts', 'Checking account', 'Purpose']\n",
    "\n",
    "# Define the pipeline steps\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipeline_steps = [\n",
    "    ('label_encoder', LabelEncoderTransformer(columns=label_encode_columns)),\n",
    "    ('binary_encoder', BinaryEncoder(columns=['Sex', 'Risk'])),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Use SimpleImputer\n",
    "    ('scaler', RobustScaler())\n",
    "]\n",
    "# Initialize the pipeline\n",
    "pipeline = Pipeline(pipeline_steps)\n",
    "\n",
    "# Apply the pipeline to the data\n",
    "df_transformed = pipeline.fit_transform(df)  # df is your original dataframe\n",
    "\n",
    "# Convert transformed data back to a DataFrame for easier inspection\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=df.columns) \n",
    "\n",
    "# Output the transformed DataFrame\n",
    "df_transformed\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming your data string is stored in a variable named 'data_string'\n",
    "# data_list = data_string.split('\\n')\n",
    "\n",
    "# # Define your desired column names\n",
    "# column_names = ['Age', 'Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Credit amount', 'Duration', 'Purpose', 'Risk']  # Replace with your actual column names\n",
    "\n",
    "# # Create a DataFrame with the specified column names\n",
    "# df = pd.DataFrame([x.split() for x in data_list], columns=column_names)\n",
    "\n",
    "# # Now, your DataFrame will have the desired column names\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9c19a-ac86-409a-9a9f-3b14e5847ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
